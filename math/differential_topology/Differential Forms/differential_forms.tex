\documentclass[11pt, oneside]{article}   	% use "amsart" instead of "article" for AMSLaTeX format
\usepackage[margin = 1in]{geometry}                		% See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   		% ... or a4paper or a5paper or ... 
%\geometry{landscape}                		% Activate for rotated page geometry
%\usepackage[parfill]{parskip}    		% Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}				% Use pdf, png, jpg, or epsÂ§ with pdflatex; use eps in DVI mode
								% TeX will automatically convert eps --> pdf in pdflatex		
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage[shortlabels]{enumitem}
\usepackage{float}
\usepackage{tikz-cd}

\usepackage{amsthm}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{example}{Example}[section]
\newtheorem{lemma}[theorem]{Lemma}

\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}

%SetFonts

%SetFonts


\title{Differential Forms}
\author{Patrick Oare}
\date{}							% Activate to display a given date or no date

\begin{document}
\maketitle

Differential forms generalize the notion of integration over Euclidean space to an arbitrary smooth manifold. Although they take 
a bit of manifold theory to even get to the definition, they are very useful for all areas of math and physics. In particular, they 
provide the ultimate generalization of multivariable calculus. We will see that there is a general analog of Stokes' theorem which 
is the origin of all the fundamental theorems of calculus you have studied (i.e. the one-dimensional version, divergence theorem, 
Green's theorem, etc.). 

Once we work up to the definition of a form and how to integrate such an object, we will turn to cohomology theories which 
stem from the existence of forms. Namely, we will study the de Rham complex on a manifold, which is the cochain complex 
generated by the exterior derivative. We will then turn to \v{C}ech cohomology and its similarities with the de Rham 
cohomology. 

\section{Background}

I will most likely write this up into a separate notes on differential manifolds later, but for now I will state the main definitions 
and theorems that we will need to study forms. I will assume the reader is familiar with the definition of a differentiable 
manifold $M$, but we will briefly recap the definitions for notations sake. 

Note in these notes unless otherwise specified we will use summation convention, so any repeated index is summed over. 
We will also try to be accurate with upper and lower indices. 

\subsection{Smooth Manifolds}

A \textbf{chart} on a space is a pair $(U, \phi)$ 
such that $U\subseteq M$ is open and $\phi : U\xrightarrow{\sim}\mathbb R^n$ is a homeomorphism onto an open subset 
$\phi(U)\subseteq\mathbb R^n$. We call $n$ the 
\textbf{dimension} of $M$. A collection $\{(U_\alpha, \phi_\alpha)\}_{\alpha\in A}$ of charts which cover $M$ is called an 
\textbf{atlas} if the overlap functions $\phi_\alpha\circ\phi_\beta^{-1}$ are smooth on $\mathbb R^n$ whenever their images 
overlap; this condition on the charts is known as being \textbf{$C^\infty$ compatible}. A \textbf{smooth manifold} is a topological 
manifold with a \textbf{maximal atlas}, namely an atlas $\mathfrak M$ such that if $\mathfrak A$ is another atlas of $M$ which 
contains $\mathfrak M$, then $\mathfrak M = \mathfrak A$. 

These definitions are technical, and most likely will never be used in these notes. The important property that a smooth manifold 
$M$ has is it can be covered by charts, which put a coordinate system around every point $p\in M$. We will often write a chart 
$(U, \phi)$ as $(U, x^1, ..., x^n)$, where $x^i$ are the coordinates on the chart $U\subset M$. Formally, if we let $r^i : \mathbb 
R^n\rightarrow\mathbb R$ be the coordinate functions on $\mathbb R^n$, then the coordinates $x^i$ are defined as 
$x^i := r^i\circ\phi$. 

A function $f : M\rightarrow\mathbb R$ is \textbf{smooth}, or $C^\infty$, at a point $p\in M$ if there is a chart $(U, \phi)$ about 
$p$ such that $f\circ \phi^{-1} : \mathbb R^n\rightarrow\mathbb R$ is smooth as a map between Euclidean spaces. $f$ is a 
\textbf{smooth function} if it is smooth at each $p\in M$. We use the notation:
\begin{equation}
	C^\infty(M) := \{ f : M\rightarrow\mathbb R \; | \; f \textnormal{ is smooth.}\}
\end{equation}
A map $f : M\rightarrow N$ between two manifolds $M$ and $N$ (of dimensions $m$ and $n$, respectively) is said to be 
\textbf{smooth} at $p\in M$ if there are charts $(U, \phi)$ about $p\in M$ and $(V, \psi)$ about $f(p)\in N$ such that the 
composition $\psi\circ f\circ\phi^{-1} : \mathbb R^m\rightarrow\mathbb R^n$ is smooth. $f$ is smooth if it is smooth at each point 
in $M$. A \textbf{diffeomorphism} is an isomorphism in the category of smooth manifolds, and it is a bijective $C^\infty$ map $M
\rightarrow N$ which has a smooth inverse. If $F : M\rightarrow N$ is a map and $(V, y^1, ..., y^n)$ is a chart about $\phi(p)\in 
N$, then the components of $F$ are functions $F^i := y^i\circ F : F^{-1}(V)\subset M\rightarrow\mathbb R$, and $F$ is 
smooth iff its component functions are smooth on each chart (by the overlap condition, if $F^i$ is smooth on one chart then it 
is smooth on every chart). 

We can extend the notion of differentiation immediately to $C^\infty$ functions given a chart. Let $p\in M$ be contained by 
a chart $(U, \phi)$. Let $r^i$ be the standard coordinates on $\mathbb R^n$ and push these to coordinates $x^i$ on $M$. For
$f\in C^\infty(M)$ the \textbf{partial derivative} of $f$ at $p\in M$ is:
\begin{equation}
	\frac{\partial}{\partial x^i}\bigg|_p f := \frac{\partial f}{\partial x^i}(p) := \frac{\partial}{\partial r^i}\bigg|_{\phi(p)} (f\circ\phi^{-1})
\end{equation}
where the last expression is defined as a derivate on $\mathbb R^n$. Note that $\partial x^i / \partial x^j = \delta^i_j$, as it 
should. 

We conclude this section by stating the Inverse Function Theorem. A map $f : M\rightarrow N$ is called \textbf{locally 
invertible} at a point $p\in M$ if there is a neighborhood $U$ about $p$ such that $f|_U : U\rightarrow f(U)$ is a 
diffeomorphism. 
\begin{theorem}[Inverse Function Theorem]
	Let $f : M\rightarrow N$ be a map between two manifolds of the same dimension, and $p\in M$. Let $(U, x^i)$ be a 
	chart about $p$, and suppose that there is a chart $(V, y^i)$ about $f(p)$ such that $f(U)\subseteq V$. Then $f$ is 
	locally invertible iff the Jacobian determinant is nonzero, i.e. iff
	\begin{equation}
		det\left(\frac{\partial f^i}{\partial x^j}(p)\right)\neq 0
	\end{equation}
	where $f^i = y^i\circ f$. 
\end{theorem}

\subsection{The Tangent Bundle}

To each point $p$ on a manifold $M$, we can associate a space of tangent vectors, called the \textbf{tangent space} 
and denoted $T_p M$. Visualizing this in your head provides good intuition, but it is not perfect; namely, when you 
visualize tangent vectors to a point, you tend to think of the manifold being embedded into a higher dimensional Euclidean 
space. Although manifolds often come with such an embedding, we want a way to define tangent vectors independent of 
embedding in a larger space-- a way to define a tangent space that is intrinsic to the manifold itself. To do this, we note 
that for each tangent vector $v\in T_p M$, we can define a curve $\alpha : (-\epsilon, \epsilon)\rightarrow M$ such that 
$\alpha(0) = p$ and $\alpha'(0) = v$. In other words, we can find a curve running through $p$ whose derivative is $v$. 

One way to make this definition is to define the tangent space as the tangent vectors of curves running through the point, but 
we will take a slightly different approach. For us, a tangent vector will be defined as an operator which acts like a directional 
derivative, since for each vector we can associate a such a directional derivative. For a function $f\in C^\infty(M)$, we define 
the \textbf{germ} of $f$ at $p$ to be the class of functions which equal $f$ on some open neighborhood about $p$. This is 
an equivalence relation $\sim$ on $C^\infty(M)$, and we denote by $C_p^\infty(M)$ the set of germs of $C^\infty(M)$ functions 
at $p$. The notion of a derivative can be shown to be in one-to-one correspondence with any operator that satisfies the 
Leibniz rule, called a derivation:
\begin{definition}[Derivation, tangent vector]
	A \textbf{derivation} at a point $p\in M$ is a linear map $D : C_p^\infty(M)\rightarrow\mathbb R$ such that:
	\begin{equation}
		D(fg) = D(f) g(p) + f(p) D(g)
	\end{equation}
	A \textbf{tangent vector} at a point $p\in M$ is a derivation at $p$, and we denote the space of tangent vectors by 
	$T_pM$. 
\end{definition}

Given a chart $(U, x^i)$, the set of partial derivatives evaluated at $p$ are derivations at $p$, and in fact form a basis for the tangent space:
\begin{equation}
	\textnormal{span}\left\{\frac{\partial}{\partial x^i}\bigg|_p\right\}_{i = 1}^n = T_p M
\end{equation}
which is easy to prove. The tangent space of an $n$-dimensional manifold is thus an $n$-dimensional vector space. So, given 
a tangent vector $X_p\in T_p M$, we define $X_p$ by its action $X_p f$ on functions $f\in C^\infty(M)$ (since we can drop 
each function down to the germs at $p$, $C_p^\infty(M)$). We can similarly expand it about the derivatives:
\begin{equation}
	X_p = \sum_{i = 1}^n X^i\partial_i
\end{equation}
where $X^i$ are the coordinates of the vector $X$. 

Given a map $f : M\rightarrow N$, we get a natural map $f_* : T_p M\rightarrow T_{f(p)} N$ for each $p\in M$ defined by:
\begin{equation}
	(f_*X_p)(g) := X_p(g\circ f)
\end{equation}
where here $g$ is a function in $C^\infty(N)$, and so $g\circ f\in C^\infty(M)$. This map is generally called the 
\textbf{push-forward}, or the \textbf{differential}. When we dualize to study covectors, we will see its analog is a natural chain 
map between the de Rham cochain complexes. The push forward can be thought of as a sort of ``derivative" since it 
approximates a smooth map as a linearized map between tangent spaces. It is often denoted as $df$ instead of $f_*$, but 
we will reserve the use of $df$ for discussing differential forms\footnote{We will see that when the exterior derivative acts on a 
map $h : M\rightarrow\mathbb R$, the one-form $dh$ is naturally the map $h_* : T_p M\rightarrow\mathbb R\in T_p^* M$, and 
so the notation $df$ and $f_*$ is really one and the same for real-valued maps in $C^\infty(M)$.} later. Indeed, it even 
satisfies a functorial chain rule.
\begin{theorem}
	Let $f : M\rightarrow N$ and $g : N\rightarrow P$ be smooth maps between manifolds. Then:
	\begin{equation}
		(g\circ f)_* = g_*\circ f_* : T_p M\rightarrow T_{(g\circ f)(p)}P
	\end{equation}
\end{theorem}
Let $U\subset M$ be open and $f : M\rightarrow N$ be a smooth map. If $f_* : T_p M\rightarrow T_{f(p)}N$ is an injective map 
as $p$ ranges over $U$, then $f$ is called an \textbf{immersion} on $U$, and if $f_*$ is surjective on $U$, then $f$ is 
called a \textbf{submersion}. 

The set of tangent spaces to a manifold naturally has a fiber bundle structure. We define the \textbf{tangent bundle} $TM$ to 
be the set:
\begin{equation}
	TM := \coprod_{p\in M} T_p M
\end{equation}
There is a natural projection map sending each vector to its base point:
\begin{align}
	\pi : TM &\rightarrow M \\
		X_p &\mapsto p
\end{align}

We can define a topology on the total space $TM$. To define this topology, consider a chart $(U, \phi) = (U, x^i)$, and let $n = 
\dim(M)$. On $TU$, we can represent a general element by $(p, v^i\partial_i) = (x^1, ..., x^n, v^1, ..., v^n)$, where $p = 
(x^1, ..., x^n)$ and the derivatives $\partial_i$ are evaluated at $p$. So, we have a natural map:
\begin{align}
	\tilde \phi : TU &\rightarrow \mathbb R^{2n} \\
	(p, v^i\partial_i) &\mapsto (x^1, ..., x^n, v^1, ..., v^n)
\end{align}
This is a bijection between $TU$ and $U\times R^n$, and so we can use this to transfer the topology of $R^{2n}$ to $TU$. 
This makes $TU$ into a topological space. Furthermore, given a maximal atlas $\{(U_\alpha, \phi_\alpha)\}$ of $M$, the 
set $\{(TU_\alpha, \tilde \phi_{\alpha *})\}$ is a maximal atlas for $TM$. So, the bundle \textbf{$TM$ is naturally a $2n$ 
dimensional manifold}. As a fiber bundle, the total space is $TM$ and the base space is $M$. 

Given a map $f : M\rightarrow N$, we can use the differential at each tangent space to define a push forward between the two 
bundles:
\begin{align}
	f_* : TM &\rightarrow TN \\
		(p, X_p) &\mapsto (f(p), f_*(X_p))
\end{align}
which is naturally a morphism of bundles. 

Recall the definition of a section of a fiber bundle.
\begin{definition}[Section]
	Let $\pi : E\rightarrow B$ be a fiber bundle. A \textbf{section} of $(\pi, E, B)$ is a continuous map $s : B\rightarrow E$ 
	such that $\pi\circ s = id_B$. A section is \textbf{smooth} if $s$ is a smooth map. We denote the set of all $C^\infty$ 
	sections of of $E$ by $\Gamma(E)$. 
\end{definition}
\begin{definition}[Frame]
	A \textbf{frame} of a vector bundle $\pi : E\rightarrow B$ over an open set $U\subseteq B$ is a collection of sections 
	$\{s_1, ..., s_r\}$ such that at each $p\in B$, $\{s_1(p), ..., s_r(p)\}$ is a basis for the fiber $\pi^{-1}(p)$. 
\end{definition}
A section\footnote{In physics, whenever we think about a ``field", we are really thinking about sections of a bundle (or we are 
just thinking about standard functions). For example, a QCD gauge field is a section of a fiber bundle with fibers $SU(3)$ over 
the base space $\mathbb R^4$. Sections are thus a concept that you've almost certainly seen before, albeit in a much less 
rigorous way.} of the tangent bundle is called a \textbf{vector field}, which is perhaps the easiest way to visualize the definition 
of a section; it is simply a continuous assignment of each base point to an element in its fiber. We denote by $\mathfrak X(M)$ 
the set of all $C^\infty$ vector fields on $M$, i.e: 
\begin{equation}
	\mathfrak X(M) := \{X\in \Gamma(TM) : X\textnormal{ is } C^\infty\}
\end{equation}
A frame on the bundle 
$TM$ is then a set of pointwise linearly independent vector fields, and the requirement that the tangent bundle has a global 
frame means that there are $n$ nowhere vanishing, linearly independent vector fields on the entire manifold. As an 
example of a frame, the vector fields $\{\partial_x, \partial_y, \partial_z\}$ form a global frame on $\mathbb R^3$. 

\subsection{Partitions of Unity}

\section{Differential Forms}

At their most basic level, differential form generalize differential notions of length, area, volume, etc. in Euclidean space to 
arbitrary manifolds. These generalize the notion of integration to manifolds, and in the next section we will see how to integrate 
a form. If I give you a vector (a one-dimensional shape) and ask you its length, what do you say? You give me a real number! 
The length $\ell$ of a vector in a space $V$ is simply a map $V\rightarrow\mathbb R$, i.e. it is a dual vector $\ell\in Hom(V, 
\mathbb R)$. 

This generalizes to higher dimensional objects, which we will take to be ``oriented products" of vectors. 
For example, in two dimensions, suppose I represent a parallelogram with sides $v$ and $w$ by some object $v\wedge w$. 
Then to have an oriented area, I must have $v\wedge w = -w\wedge v$. There is a natural construction called the 
\textbf{exterior power} of a vector space which takes in a space $V$ and spits an object with such an antisymmetric product 
of copies of $V$, and later we will use this to define a $k$-form, our generalized notion of volume. 

\subsection{1-forms}

Before working with $k$-forms, we must define 1-forms. 
\begin{definition}[Cotangent space]
	Let $p\in M$. The \textbf{cotangent space} at $p$ is the dual of the tangent space at $p$, i.e. is:
	\begin{equation}
		T_p^* M := (T_p M)^* = Hom(T_p M, \mathbb R)
	\end{equation}
	We call elements of the cotangent space \textbf{covectors}.
\end{definition}

So, a covector takes in a vector and spits out a number, i.e. if $\omega_p\in T_p^* M$, then $\omega_p(X_p)\in\mathbb R$ 
for any vector $X_p\in T_p M$. Let $(U, x^i)$ be a chart about $p\in M$. Then as $\{\partial_i\}_{i = 1}^n$ is a basis for 
$T^p M$, we have a corresponding dual basis $\{dx^i\}_{i = 1}^n$. The dual basis satisfies:
\begin{equation}
	dx^i(\partial_j) = \delta^i_j
\end{equation}
We will soon see that $dx^i$ can be determined by acting the exterior derivative on the coordinate function $x^i$, and so this 
notation is quite suggestive. Note that we can use the cotangent spaces to define a fiber bundle:
\begin{definition}[Cotangent bundle]
	The \textbf{cotangent bundle} $T^*M$ of a manifold $M$ is:
	\begin{equation}
		T^* M := \coprod_{p\in M} T_p^* M
	\end{equation}
\end{definition}
We can define a bijection with $\mathbb R^{2n}$ by sending $(x^1, ..., x^n, \omega_i dx^i)$ to the corresponding element 
$(x^1, ..., x^n, \omega_1, ..., \omega_n)$, and use this to transfer the topology to $T^*M$, making it into a smooth manifold 
just like $TM$. We can now define a 1-form (for good measure we also define a 0-form):
\begin{definition}[1-form]
	A \textbf{differential 1-form} $\omega$ is a section of the cotangent bundle, i.e. a map $\omega : M\rightarrow T^* M$ with 
	$\pi\circ \omega = id_M$. A 1-form is \textbf{smooth} if it is smooth as a map $M\rightarrow T^*M$. The set of all 
	$C^\infty$ 1-forms will be denoted by $\Omega^1(M)$, so we have:
	\begin{equation}
		\Omega^1(M) := \Gamma(T^*M)
	\end{equation}
\end{definition}
\begin{definition}[0-form]
	We define a 0-form on $M$ to be a smooth function:
	\begin{equation}
		\Omega^0(M) := C^\infty(M)
	\end{equation}
\end{definition}
We already have seen some examples of 1-forms: consider a function $f\in C^\infty(M)$. The induced push forward map 
is $f_* : T_p M\rightarrow T_{f(p)}\mathbb R$. However, there is a canonical isomorphism $\iota : T_{q}\mathbb \mathbb R
\rightarrow\mathbb R$, $a\frac{d}{dt}|_q\mapsto a\in\mathbb R$. Hence, we consider the \textbf{differential map} $df|_p 
:= \iota\circ f_*$, which is a map $T_p M\rightarrow \mathbb R$. This has the exact same action as the push-forward, we 
just ``forget" the basis vector and consider the corresponding scalar. Thus, $df|_p$ is a linear map from $T_p M$ into 
$\mathbb R$, hence is a covector, $df|_p\in T_p^* M$. As we vary $p$ across the entire manifold, we see that the map $df$ is 
in fact a section of the cotangent bundle, and thus $df$ is a 1-form, which we will soon see is a smooth 1-form. 

The explicit action of $df\in\Omega^1(M)$ on a vector $X_p\in T_pM$ is:
\begin{equation}
	df(X_p) = X_p(f)
\end{equation}
which is valued in $\mathbb R$, as $X_p$ maps $C^\infty(M)$ into $\mathbb R$. Note the difference with $f_*$; the 
push forward $f_*$ maps $X_p$ to an element of the tangent space of the codomain of $f$, while $df$ maps $X_p$ to 
a real number. For $f\in C^\infty(M)$ these are isomorphic, but it is an important distinction between the two. For example, 
$f_* X_p$ acts on functions $\mathbb R\rightarrow\mathbb R$, and its action on $h : \mathbb R\rightarrow\mathbb R$ is 
$(f_* X_p)(h) = X_p(h\circ f)$, although when we consider $df (X_p)$ we need not act it on the a function $h$ to get a 
real number; it just spits out a real number immediately.

%We're going to overload our notation 
%a bit, and we will write either $df$ or $f_*$\footnote{Technically, here we are taking $f_* : T_pM\rightarrow T_{f(p)}\mathbb R$ 
%and $df : T_p M\rightarrow\mathbb R$. This is not too important, except that technically we have the correspondence 
%$f_*(X_p) = (df|_p)(X_p) \frac{d}{dt}|_{f(p)}$ because $f_*(X_p)$ is a vector in the tangent space $T_{f(p)}\mathbb R$, while 
%$df|_p X_p$ is a scalar, and so must be multiplied by the basis vector $\frac{d}{dt}|_{f(p)}$ to be pulled into the tangent 
%space that $f_*$ maps into. These spaces are isomorphic, so there is no need to really worry about this.} for the induced 
%map $TM\rightarrow T\mathbb R$. The induced map $df : T_p M
%\rightarrow T_{f(p)}\mathbb R\cong\mathbb R$ sends an element of $T_p M$ to a scalar, and hence $df|_p$ is a covector. 
%As we vary $p$ across the entire manifold, we see that the map $df$ is in fact a section of the cotangent bundle, and 
%thus $df\in\Omega^1(M)$. We will soon generalize this to the exterior derivative. 

Consider what happens when we apply this differential to the coordinate 
functions $dx^i$. Then acting on the basis elements, by definition of the induced map we have:
\begin{equation}
	dx^i(\partial_j) = \partial_j x^i = \delta^i_j
\end{equation}
and so the original notation of $\{dx^i\}$ as the dual basis was suggestive of this actually being the differential 
of the coordinate charts! 

Now, suppose we have a function $f\in C^\infty(M)$. We can expand out $df = a_i dx^i$ in a chart $(U, x^i)$, since at 
each point $\{dx^i|_p\}$ is a basis for $T_p^* M$. To determine the coefficients $a_i$, act each side on $\partial_j$:
\begin{equation}
	df(\partial_j) = a_i dx^i(\partial_j)\implies \partial_j f = a_i\delta^i_j = a_j
\end{equation}
This implies that for any function $f\in C^\infty(M)$, the differential of a function can be written as:
\begin{equation}
	df = \frac{\partial f}{\partial x^i}dx^i
\end{equation}

Note that any 1-form $\omega = a_i dx^i$ is determined completely by the coordinate functions $a_i(p)$ for $p\in M$. It is 
a reasonably simple proof to show that $\omega$ is $C^\infty$ iff each of its coordinate functions $a_i(p)$ are $C^\infty$ as 
well. Thus we have the following corollary:
\begin{corollary}
	If $f\in C^\infty(M)$, then $df\in\Omega^1(M)$, so $df$ is a smooth 1-form. 
\end{corollary}
\begin{lemma}
	Let $\omega$ be a 1-form. If $f$ is a function and $X$ is a vector field on $M$, then $\omega(fX) = f\omega(X)$. 
\end{lemma}
Finally, note that we can scalar multiply 1-forms by functions. For $g\in C^\infty(M)$ and $\omega\in\Omega^1(M)$, we can 
define a one form $g\omega\in\Omega^1(M)$ by scalar multiplication:
\begin{equation}
	(g\omega)|_p := g(p)\omega_p
\end{equation}
Because this is scalar multiplication, $g\omega = \omega g$ since $g(p)$ can simply pull out of 1-forms, since the 
action of a 1-form $g\omega$ on a vector field $X$ at $p\in M$ is $(g\omega) X = (g\omega)|_p X_p = g(p)\omega_p X_p
= \omega_p g(p) X_p$. 

Since we have dualized the tangent bundle to define 1-forms, a map between manifolds induces a pullback map 
of forms, because the direction of the push forward map must reverse itself. 
\begin{definition}[Pullback]
Let $f : M\rightarrow N$ be a smooth map. Then at each $p\in M$, we induce the \textbf{pullback map} $f^* : T_{f(p)}^* N 
\rightarrow T_p^* M$ defined pointwise by its action on vectors:
\begin{equation}
	f^*(\omega)|_p X_p := \omega_{f(p)}(f_* X_p)
\end{equation}
We will often write these as fields and instead write this relation between sections of the tangent and cotangent bundles:
\begin{equation}
	f^*(\omega) X = \omega(f_* X)
\end{equation}
Pictorially, the following diagram commutes:
\begin{equation}\begin{tikzcd}
	T_p M\arrow[r, "f_*"] \arrow[dr, bend right, "f^*\omega"'] & T_p N \arrow[d, "\omega"] \\
	& \mathbb R
\end{tikzcd}\end{equation}
Let $\omega\in\Omega^1(N)$ be a 1-form. Then $f^*$ extends to a pullback on 1-forms:
\begin{equation}
	f^* : \Omega^1(N) \rightarrow\Omega^1(M)
\end{equation}
by pulling back each form pointwise, $f^*(\omega)|_p := f^*(\omega_p)$. 
\end{definition}

Any map can also pull back a function $g\in C^\infty(M)$ by precomposition, i.e. we get an induced map $f^* : C^\infty(N)
\rightarrow C^\infty(M)$, $f^*(g) := g\circ f$, and so we have pullbacks $f^* : \Omega^k(N)\rightarrow\Omega^k(M)$ for $k\in 
\{0, 1\}$. There are a few particularly important properties of the pullback. These will later generalize and show us that $f^*$ is 
a chain map on the de Rham complex, but for now we will show how this works with the differential $d : \Omega^0(M)
\rightarrow \Omega^1(M)$. 
\begin{theorem}
	Let $f : M\rightarrow N$ be a $C^\infty$ map between manifolds. Then the induced map $f^* : \Omega^k(N)\rightarrow 
	\Omega^k(M)$ for $k = 0, 1$ satisfies:
	\begin{enumerate}
		\item $f^* d = df^*$, i.e. the following diagram commutes:
		\begin{equation}\begin{tikzcd}
			C^\infty(N)\arrow[r, "f^*"]\arrow[d, "d"] & C^\infty(M) \arrow[d, "d"] \\
			\Omega^1(N)\arrow[r, "f^*"] & \Omega^1(M)
		\end{tikzcd}\end{equation}
		\item $f^*(\omega + \tau) = f^*\omega + f^*\tau$.
		\item For $g\in C^\infty(N)$, $f^*(g\omega) = (f^*g)(f^*\omega)$. 
	\end{enumerate}
\end{theorem}
\begin{proof}
	We prove the first by picking $g\in C^\infty(N)$, and act $df^*(g)$ and $f^*(dg)$ (both in $\Omega^1(M)$ on $X_p\in T_p 
	M$, as if these agree for arbitrary $X_p$ then they are equal as linear functionals). We have:
	\begin{equation}
		df^*(g) X_p = d(g\circ f) X_p = (g\circ f)_* X_p = X_p(g\circ f)
	\end{equation}
	\begin{equation}
		f^*(dg) X_p = dg(f_* X_p) = (f_*X_p)(g) = X_p(g\circ f)
	\end{equation}
	For 2, we $\omega, \tau\in\Omega^1(N)$ and must these on vectors $X\in TM$. This gives:
	\begin{equation}
		f^*(\omega + \tau)(X) = (\omega + \tau)(f_* X) = \omega f_* X + \tau f_* X = f^*(\omega)X + f^*(\tau) X
	\end{equation}
	For 3, we act this on $X_p\in T_p M$ and have:
	\begin{equation}
		f^*(g\omega) X_p = (g\omega)_{f(p)} (f_* X_p) = g(f(p)) \omega_{f(p)}(f_* X_p) = (f^* g)(f^*\omega) X_p
	\end{equation}
\end{proof}
This quick proof is a nice example to recall what the different types of maps do, and to work through it, and the best 
way to work through it is to draw out all the maps and induced maps. Note that although relations between 1-forms, vector 
fields, functions, and other objects are simplest to write out as sections of a bundle (i.e. vector / covector valued fields), when 
we do computations with them we typically pick a point $p\in M$ to do the computation over. 

\subsection{$k$-forms}

At this point, we turn towards differential $k$-forms. If you are not familiar with the idea of the exterior algebra to a vector 
space, it would be a good idea to read my notes on module theory and familiarize yourself with it. Differential forms are 
exactly sections of the $k$th exterior power of the cotangent bundle; by taking the exterior power, we make forms 
implicitly antisymmetric, which makes them useful to define orientations. 

Recall that for a vector space $V$, $\Lambda^k V$ is the quotient of $\bigotimes_k V$ by the ideal generated by 
$\{x_1\otimes ...\otimes x_k : x_i = x_j, i\neq j\}$. The image of $\otimes$ in this algebra is denoted by the wedge product 
$\wedge$, and the exterior algebra of $V$ is $\Lambda^* V := \bigoplus_{k = 0}^\infty\Lambda^k V$. The exterior 
algebra $(\Lambda^* V, +, \times, \wedge)$ is the ``best antisymmetric product" of $V$, as any alternating map from 
$V^k$ to $\mathbb R$ factors to a linear map $\Lambda^* V\rightarrow\mathbb R$. 

\begin{definition}[Alternating map]
	A map $f : V^k\rightarrow K$ for a field $K$ and a $K$-vector space $V$ is called \textbf{alternating} if for each $\sigma
	\in S_k$, we have:
	\begin{equation}
		f(v_{\sigma (1)}, ..., v_{\sigma (k)}) = \textnormal{sgn}(\sigma) f(v_1, ..., v_k)
	\end{equation}
	where $\{v_1, ..., v_k\}\subseteq V$. 
\end{definition}

To study differential forms, let $p\in M$ and consider the $k$th exterior power of the cotangent space $\Lambda^k(T_p^* M)$. 
We can vary $p\in M$ and take a union to form a fiber bundle over $M$, called the $k$th exterior power of the cotangent 
bundle, and a section of this bundle is called a differential form.
\begin{definition}[Differential form]
	The \textbf{$k$th exterior power of the cotangent bundle} is the fiber bundle:
	\begin{equation}
		\Lambda^k(T^* M) := \coprod_{p\in M}\Lambda^k(T_p^* M)
	\end{equation}
	A \textbf{$k$-covector} is an element of this set. A smooth section of $\Lambda^k(T^* M)$ is called a \textbf{differential 
	form}, and we call $k$ its \textbf{rank}. We denote the set of all $k$-forms on a manifold $M$ by $\Omega^k(M)$, so:
	\begin{equation}
		\Omega^k(M) := \Gamma\left(\Lambda^k(T^* M)\right)
	\end{equation}
\end{definition}
Note $\Lambda^k(T_p^* M)$ is in bijection with the space of $k$-linear, alternating maps $(T_p^* M)^k\rightarrow\mathbb R$, 
so we may equivalently view a differential form as an alternating map on the tangent space at each point $p\in M$:
\begin{align}
	\omega\in\Omega^k(T^*M) &\iff\forall p\in M, \;\omega_p\in\Lambda^k(T^*M) \\
	&\iff\forall p\in M, \;\omega_p : (T_p M)^k\rightarrow \mathbb R\textnormal{ is linear and alternating}
\end{align}
We will typically view a differential form as an alternating map, as working with the abstract definition of a $k$-covector 
is very difficult to deal with and does not give us much. 

A differential form is a specific example of a tensor field.
\begin{definition}[Tensor]
	Let $p\in M$. A \textbf{tensor} at $p$ is a multilinear map:
	\begin{equation}
		F : (T_p M)^k\times (T_p^* M)^\ell\rightarrow\mathbb R
	\end{equation}
	where $k, \ell\in\mathbb N_{\geq 0}$. We say the tensor has \textbf{type} $(k, \ell)$. 
\end{definition}
A differential form of rank $k$ may thus equivalently be categorized as an \textbf{alternating tensor of type} $\bf{(0, k)}$ (where 
by an alternating tensor we mean it is an alternating map), and this definition often appears in literature. 

Consider $k$ vector fields $\{X_1, ..., X_k\}$ on $M$. Then we 
get a function $\omega(X_1, ..., X_k) : M\rightarrow\mathbb R$, $p\mapsto \omega_p((X_1)_p, ..., (X_k)_p)$. Because 
$\omega$ is an alternating function, note that for example $\omega(X_1, X_2, ..., X_k) = -\omega(X_2, X_1, ..., X_k)$ and 
so on. This function is linear with respect to functions $h : M\rightarrow\mathbb R$ in the sense that:
\begin{equation}
	\omega(X_1, ..., hX_i, ..., X_k) = h\omega(X_1, ..., X_i, ..., X_k)
\end{equation}
for each $i$. 

We now consider what a general differential form looks like for a chart $(U, x^i)$. At each $p\in M$, $\{dx^i|_p\}_{i = 1}^n$ is a 
basis for the cotangent space. Because we are taking the $k$th exterior power, a basis is thus formed by taking all the 
combinations:
\begin{equation}
	\beta = \{dx^{i_1}\wedge ...\wedge dx^{i_k} : 1\leq i_1 < i_2 < ... < i_k \leq n\}
\end{equation}
Note that this implies \textbf{the dimension of this exterior power is $dim(\Lambda^k(T_p^* M)) = {n\choose k}$, and 
$\Lambda^k(T_p^* M)$ vanishes for $k > n$}. A succinct way to write this is with a multi-index:
\begin{definition}[Multi-index]
	Let $k, n\in\mathbb N_{\geq 0}$. A \textbf{multi-index} between $1$ and $n$ of length $k$ is an ordered $k$-tuple 
	of the form:
	\begin{equation}
		I = (i_1, ..., i_k)
	\end{equation}
	such that $1\leq i_1< ...< i_k\leq n$. We let $\mathfrak I_k^n$ denote the set of all multi-indices between 1 and $n$ of 
	length $k$. 
\end{definition}
With this notation, we may write a basis for $\Lambda^k(T_p^*M)$ as $\{dx^I : I\in\mathfrak I_k^n\}$, where by $dx^I$ we 
mean $I = (i_1, ..., i_k)$ and $dx^I = dx^{i_1}\wedge ...\wedge dx^{i_k}$. So, we may expand each $k$-covector $\omega_p
\in\Lambda^k(T_p^* M)$ as a linear combination:
\begin{equation}
	\omega_p = a_{i_1, ..., i_k}(p)dx^{i_1}|_p\wedge ...\wedge dx^{i_k}|_p = \sum_{I\in\mathfrak I_k^n} a_I(p) dx^I|_p
\end{equation}
This implies a $k$-form $\omega\in\Omega^k(M)$ can be expanded as:
\begin{equation}
	\omega = a_{i_1, ..., i_k}dx^{i_1}\wedge ...\wedge dx^{i_k} = \sum_{I\in\mathfrak I_k^n} a_I dx^I~
	\label{eq:k_form}
\end{equation}
A $k$-form $\omega$ represented by Equation~\ref{eq:k_form} is \textbf{smooth} (so $\omega\in\Omega^k(M)$) if and only if 
$a_I : M\rightarrow\mathbb R$ is smooth as a function on $M$. For each $p\in M$, the $k$-covectors $\Lambda^k(T_p^* M)$ 
are a vector space over $\mathbb R$. When we extend to sections of $\Lambda^k(T^* M)$ to form $\Omega^k(M)$, we 
thus see that $\Omega^k(M)$ has the structure of a module over $C^\infty(M)$, as we can multiply a differential 
form pointwise by a smooth function and still have a smooth section of $\Lambda^k(T^* M)$. However, we will mostly 
be concerned with the vector space structure of $\Omega^k(M)$, as this will drop to the cohomology. $\Omega^k(M)$ is a 
real valued vector space of uncountable dimensions (as different functions $f_I(x)\,dx^I$ will generate different linearly 
independent elements). We now switch gears a bit to induced maps.
\begin{definition}[Pullback]
	Let $f : M\rightarrow N$ be $C^\infty$. Then there is an induced map:
	\begin{equation}
		f^* : \Lambda^k\left(T_{f(p)}^* N\right)\rightarrow\Lambda^k\left(T_p^* M\right)
	\end{equation}
	which sends a $k$-covector $\omega_{f(p)}$ to $f^*(\omega_{f(p)})$ which acts on $\left(T_p^M\right)^k$ as follows:
	\begin{equation}
		f^*(\omega_{f(p)})(x_1, ..., x_k) := \omega_{f(p)}(f_* x_1, ..., f_* x_k)
	\end{equation}
	for $x_i\in T_p M$. This extends to a \textbf{pullback map} of forms $f^* : \Omega^k(N)\rightarrow\Omega^k(M)$ which 
	acts on vector fields:
	\begin{equation}
		f^*(\omega)(X_1, ..., X_k) := \omega(f_* X_1, ..., f_* X_k)
	\end{equation}
\end{definition}
\begin{lemma}
	Let $f : M\rightarrow N$ be $C^\infty$. If $\omega, \tau\in\Omega^k(N)$ and $a\in\mathbb R$, then:
	\begin{enumerate}
		\item $f^*(\omega + \tau) = f^*\omega + f^*\tau$. 
		\item $f^*(a\omega) = af^*\omega$. 
		\item If $\omega$ is $C^\infty$, then $f^*\omega$ is $C^\infty$ as well. 
	\end{enumerate}
\end{lemma}

\subsection{The wedge product}

We now turn to the wedge product, which will give the space of differential $k$-forms an algebra product. Abstractly, this 
is the same wedge product that is studied when the exterior power $\Lambda^k(T_p^* M)$ is considered, and extends 
to sections $\Omega^k(M)$ pointwise. We have already used this wedge product in the previous section. However, we will 
define this in a more concrete way than as ``the image of the tensor product operation in the quotient $\Lambda^k(\cdot)$". 
We first define the wedge product generally on a vector space $V$. 

\begin{definition}[Wedge product]
	Let $V$ be a vector space, $\alpha\in\Lambda^k(V^*)$, and $\beta\in\Lambda^\ell(V^*)$ be two alternating 
	tensors\footnote{Another common notation is to denote the space of alternating tensors 
	$\Lambda^k(V^*)$ by $A^k(V)$.}. Then we define their \textbf{wedge product} to be an alternating tensor 
	$\alpha\wedge\beta\in\Lambda^{k + \ell}(V^*)$ such that:
	\begin{equation}
		(\alpha\wedge\beta)(v_1, ..., v_{k + \ell}) := \frac{1}{k!\ell!}\sum_{\sigma\in S_{k + \ell}}sgn(\sigma)
		\alpha(v_{\sigma(1)}, ..., v_{\sigma(k)})\beta(v_{\sigma(k + 1), ..., v_{\sigma(k + \ell)}})~
		\label{eq:wedge}
	\end{equation}
	where $S_n$ is the symmetric group on $n$ letters. 
\end{definition}

The wedge product may be rewritten as a slightly simpler sum without the extra factorial factors. We define a 
$\bf{(k, \ell)}$-\textbf{shuffle} to be a permutation $\tau\in S_{k + \ell}$ such that:
\begin{equation}
	\tau(1) < ... < \tau(k) \& \tau(k + 1) < ... < \tau(k + \ell)
\end{equation}
Essentially, $\tau$ mixes the sets $\{1, ..., k\}$ and $\{k + 1, ..., \ell\}$ in increasing order. Let $\mathfrak S_{k, \ell}\subseteq
S_{k + \ell}$ be the set of all $(k, \ell)$ shuffles. Then Equation~\ref{eq:wedge} may be rewritten as:
\begin{equation}
	(\alpha\wedge\beta)(v_1, ..., v_{k + \ell}) = \sum_{\tau\in\mathfrak S_{k, \ell}}sgn(\tau)\alpha(v_{\tau(1)}, ..., v_{\tau(k)})
	\beta(v_{\tau(k + 1)}, ..., v_{\tau(k + \ell)})
\end{equation}
The wedge product is totally anticommutative in the graded sense, in that if $\alpha\in\Lambda^k(V^*)$ and $\beta\in
\Lambda^\ell(V^*)$, then:
\begin{equation}
	\alpha\wedge\beta = (-1)^{k\ell}\beta\wedge\alpha
\end{equation}
This implies that for any $k$-covector of odd degree $\alpha\in\Lambda^{2k}(V^*)$, $\alpha\wedge\alpha = 0$. The wedge 
product is also associative, and this associativity will give the spaces $\Omega^k(M)$ an algebra structure. One final nice 
property of the wedge product is that for $\alpha^1, ..., \alpha^k\in V^*$ and $v_1, ..., v_k\in V$, then:
\begin{equation}
	(\alpha^1\wedge ...\wedge\alpha^k)(v_1, ..., v_k) = \det\{a^i(v_j)\}
\end{equation}

Now, we turn to using the wedge product as an operation on forms. 
\begin{definition}
	Let $\omega\in\Omega^k(M)$ and $\tau\in\Omega^\ell(M)$ be two differential forms. Then we define their \textbf{wedge 
	product} to be $\omega\wedge\tau\in\Omega^{k + \ell}(M)$ defined pointwise as a wedge product on covectors:
	\begin{equation}
		(\omega\wedge\tau)_p :=\omega_p\wedge\tau_p
	\end{equation}
\end{definition}
It is easy to show that $\omega\wedge\tau$ is $C^\infty$ if both $\omega$ and $\tau$ are. This structure makes 
$(\Omega^k(M), +, \cdot, \wedge)$ into algebra. We can further define the \textbf{algebra of $C^\infty$ differential forms} 
$\Omega^*(M)$ as:
\begin{equation}
	\Omega^*(M) := \bigoplus_{k = 0}^\infty\Omega^k(M)
\end{equation}
Then $(\Omega^*, +, \cdot, \wedge)$ is naturally a graded algebra over $\mathbb R$, and we will soon associate a differential 
with it to make it into a cochain complex. The pullback $f^*$ is also an algebra homorphism.
\begin{theorem}
	Let $f : M\rightarrow N$ be smooth. Then the pullback respects $\wedge$, i.e. if $\omega\in\Omega^k(N), 
	\tau\in\Omega^\ell(N)$ are differential forms on $N$, we have:
	\begin{equation}
		f^*(\omega\wedge\tau) = f^*(\omega)\wedge f^*(\tau)
	\end{equation}
\end{theorem}
\begin{proof}
	This is simply by working through the definitions. Act $f^*(\omega\wedge\tau)$ on vectors $X_1, ..., X_{k + \ell}\in T_p M$:
	\begin{align}
		f^*(\omega\wedge\tau)_p(X_1, ..., X_{k + \ell}) &= (\omega_p\wedge\tau_p)(f_* X_1, ..., f_* X_{k + \ell})\\
		&= \sum_{\sigma\in\mathfrak S_{k, \ell}}sgn(\sigma) \omega_p(f_* X_{\sigma(1)}, ..., f_* X_{\sigma(k)})
		\tau_p(f_* X_{\sigma(k + 1)}, ..., f_* X_{\sigma(k + \ell)}) \\
		&= \sum_{\sigma\in\mathfrak S_{k, \ell}}sgn(\sigma) f^*(\omega_p)(X_{\sigma(1)}, ..., X_{\sigma(k)})f^*(\tau_p)
		(X_{\sigma(k + 1)}, ..., X_{\sigma(k + \ell)}) \\
		&= (f^*(\omega_p)\wedge f^*(\tau_p))(X_1, ..., X_{k + \ell})
	\end{align}
\end{proof}

\subsection{The Exterior Derivative}

We come to the last few major definitions for differential forms: we will first define a coboundary map, called the \textbf{exterior 
derivative}, that generalizes the standard derivative in $\mathbb R^n$ and gives $\Omega^*(M)$ the structure of a 
graded cochain complex. Later, we will generalize the notion of a derivative to a \textbf{Lie derivative}, and show that this 
is intimately connected with the exterior derivative. 

\begin{definition}[Antiderivation]
	Let $A = \bigoplus_{k = 0}^\infty A^k$ be a graded algebra. A \textbf{antiderivation} on $A$ is a $\mathbb R$-linear map 
	$D : A\rightarrow A$ such that for $\omega\in A^k$ and $\tau\in A^\ell$:
	\begin{equation}
		D(\omega\cdot\tau) = D(\omega)\cdot\tau + (-1)^k\omega\cdot D(\tau)
	\end{equation}
	We say the antiderivation has \textbf{degree} $m$ if $\deg D(\omega) = \omega + m$ for each $\omega\in A^k$. 
\end{definition}

\begin{definition}[Exterior derivative]
	An \textbf{exterior derivative} on a manifold $M$ is a $\mathbb R$-linear map $d : \Omega^*(M)\rightarrow\Omega^*(M)$ 
	such that:
	\begin{enumerate}
		\item $d$ is an antiderivation of degree 1. 
		\item $d^2 = 0$. 
		\item If $f\in C^\infty(M)$ and $X$ is a smooth vector field on $M$, then:
		\begin{equation}
			(df)(X) = X(f)
		\end{equation}
	\end{enumerate}~
	\label{def:derivative}
\end{definition}

From condition 3 of the definition, it is clear that the differential $d : \Omega^0(M)\rightarrow\Omega^1(M)$ that we have 
defined in the previous section will be the action of the exterior derivative on $0$-forms. This then means that if we 
take $\omega\in\Omega^k(M)$, when we expand $\omega = a_{i_1, ..., i_k} dx^{i_1}\wedge ...\wedge dx^{i_k}$, we have:
\begin{equation}
	d\omega = (da_I)\wedge dx^I + a_I D(dx^I) = \frac{\partial a_{i_1, ..., i_k}}{\partial x^j}dx^j\wedge dx^{i_1}\wedge ... 
	\wedge dx^{i_k}
\end{equation}

Thus on any chart $(U, x^i)$, we can define an exterior derivative on $U$ by:
\begin{equation}
	d\omega := da_I\wedge dx^I = \frac{\partial a_I}{\partial x^j} dx^j\wedge dx^I
\end{equation}
for $\omega = a_I dx^I$. It turns out that this definition is independent of the chart we have picked, and this proves the 
existence of such an exterior derivative. Furthermore, the exterior derivative defined in this way is unique, and we state 
this as a theorem.
\begin{theorem}
	There is a unique exterior derivative $d : \Omega^*(M)\rightarrow\Omega^*(M)$ which agrees with all the all the 
	properties in Definition~\ref{def:derivative}. 
\end{theorem}

The exterior derivative is a natural map which gives $\Omega^*(M)$ the structure of a cochain complex because it squares to 
0:
\begin{equation}\begin{tikzcd}
	\Omega^0(M)\arrow[r, "d"] & \Omega^1(M) \arrow[r, "d"] & \Omega^2(M)\arrow[r, "d"] & \Omega^3(M)\arrow[r, "d"] & ...
\end{tikzcd}\end{equation}
Furthermore, the pullback that was studied in the previous section is indeed a chain map with respect to $(\Omega^*(M), d)$. 
\begin{theorem}
	Let $f : M\rightarrow N$ be smooth. Then the pullback $f^* : \Omega^*(N)\rightarrow\Omega^*(M)$ is a chain map, 
	i.e. the diagram commutes:
	\begin{equation}\begin{tikzcd}
		...\arrow[r, "d"] & \Omega^{k - 1}(N)\arrow[r, "d"]\arrow[d, "f^*"] & \Omega^k(N)\arrow[r, "d"]\arrow[d, "f^*"] &
		\Omega^{k + 1}(N)\arrow[r, "d"]\arrow[d, "f^*"] & ... \\
		...\arrow[r, "d"] & \Omega^{k - 1}(M)\arrow[r, "d"] & \Omega^k(M)\arrow[r, "d"] & \Omega^{k + 1}(M)\arrow[r, "d"] & 
		...
	\end{tikzcd}\end{equation}
\end{theorem}
\begin{proof}
	Let $\omega\in\Omega^k(N)$. We must show that $f^* d\omega = d f^*\omega\in\Omega^{k + 1}(M)$. We expand 
	$\omega = a_I dx^I$. Recall we have already shown $f^* dg = df^* g$ for $g\in C^\infty(M)$. Then:
	\begin{equation}
		df^*\omega = d\left[(f^* a_I) f^* dx^{i_1}\wedge ... \wedge f^* dx^{i_k}\right] = d\left[(a_I\circ f) df^{i_1}\wedge ... 
		\wedge df^{i_k}\right] = d(a_I\circ f)\wedge df^I
	\end{equation}
	\begin{equation}
		f^*d\omega = f^*\left[da_I\wedge dx^I\right] = f^* da_I\wedge f^* dx^{i_1}\wedge ...\wedge f^* dx^{i_k}
		= d(a_I\circ f)\wedge df^I
	\end{equation}
\end{proof}

We will study the cochain complex $(\Omega^*(M), d)$ further later in these notes when we consider the cohomology obtained 
from this complex. It is called the \textbf{de Rham cohomology}, and is an essential tool in the study of smooth manifolds. 

\subsection{The Lie Derivative}

We now seek to find a nice coordinate independent way to express the exterior derivative, which we will do by introducing 
the Lie derivative. We will denote by $\{X_t\}$ or $\{\omega_t\}$ a 1-parameter family of vector fields or manifolds, where 
$t$ is varied over some subset of $\mathbb R$. For a coordinate chart $(U, x^i)$, we may expand $X_t = a^i(t, p)\partial_i|_p$. 
We say $\lim_{t\rightarrow t_0}X_t$ exists if for each $p\in M$ and $i = 1, ..., n$, $\lim_{t\rightarrow t_0} a^i(t, p)$ exists, and 
if this limit exists we set it equal to the pointwise limit. We do the same thing with a 1-parameter family $\omega_t$ of 
$k$-forms, and expand $\omega_t = b_J(t, p) dx^J|_p$. Naturally, we can define a derivative of these objects:
\begin{equation}
	\left(\frac{d}{dt}\bigg|_{t = t_0} X_t\right)_p := \frac{\partial a^i}{\partial t}(t_0, p)\partial_i|_p
	\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;
	\left(\frac{d}{dt}\bigg|_{t = t_0} \omega_t\right)_p := \frac{\partial b_J}{\partial t}(t_0, p)dx^J
\end{equation}
Note that $dX_t / dt$ and $d\omega_t / dt$ respectively remain 1-parameter families of vector fields and $k$-forms. This 
1-parameter derivative has some nice properties which we state here.
\begin{theorem}
	Let $\omega_t, \tau_t$ be smooth 1-parameter families of $k$-forms. Then:
	\begin{itemize}
		\item $d / dt$ satisfies the product rule:
		\begin{equation}
			\frac{d(\omega_t\wedge\tau_t)}{dt} = \frac{d\omega_t}{dt}\wedge\tau_t + \omega_t\wedge\frac{d\tau_t}{dt}
		\end{equation}
		\item $d / dt$ commutes with the differential:
		\begin{equation}
			\frac{d}{dt}\bigg|_{t = t_0} d\omega_t = d\left(\frac{d}{dt}\bigg|_{t = t_0}\omega_t\right)
		\end{equation}
	\end{itemize}
\end{theorem}

Recall the definition of an integral curve and a local flow. Given a vector field $X\in\mathfrak X(M)$, an integral curve of $X$ is 
a curve $\gamma$ for which $X$ is a tangent vector field to $\gamma$ at each point on the curve. A local flow generated by 
$X$ is a neighborhood $W$ and a family of curves $F_t(q)$ for each $q\in W$ such that $F_t(q)$ is an integral curve of 
$X$ starting at each $q\in W$ in a ``nice" manner. More formally:
\begin{definition}[Integral curve]
	Let $X\in\mathfrak X(M)$. A curve $\gamma : (a, b)\rightarrow M$ is an \textbf{integral curve} of $X$ if $\gamma'(t) = 
	X_{\gamma(t)}$ at each $t\in (a, b)$. An integral curve is called \textbf{maximal} if its domain cannot be extended to a 
	larger interval.
\end{definition}
\begin{definition}[Local Flow]
	Let $X\in\mathfrak X(M)$. A \textbf{local flow} generated by $X$ about point $p$ in an open set $U$ is a $C^\infty$ 
	function $F : (-\epsilon, \epsilon)\times W\rightarrow U$ for $\epsilon > 0$ on neighborhood $p\in W\subseteq U$ such 
	that for each $q\in W$, we have:
	\begin{itemize}
		\item $F_t(q)$ is an integral curve of $X$. 
		\item $F_0(q) = q$. 
		\item $F_t(F_s(q)) = F_{t + s}(q)$ whenever both sides are defined. 
	\end{itemize}
\end{definition}

Given $X\in\mathfrak X(M)$ and $p\in M$, we will take for granted the existence of a neighborhood $p\in U$ for which there is 
a local flow $\phi : (-\epsilon, \epsilon)\times U\rightarrow M$ generated by $X$, so:
\begin{equation}
	\frac{\partial\phi_t(q)}{\partial t} = X_{\phi_t(q)}
\end{equation}
and $\phi_0(q) = q$. Note that in particular, $\phi_{-t}\circ\phi_t = \phi_0 = 1$. We will use this to define the Lie derivative, 
which we will define for vector fields and $k$-forms. 
\begin{definition}[Lie derivative]
	Let $X\in\mathfrak X(M)$, $p\in M$, and $\phi : (-\epsilon, \epsilon)\times U\rightarrow M$ a local flow of $X$ on a 
	neighborhood $U\ni p$. 
	Let $Y\in\mathfrak X(M)$, and $\omega\in\Omega^k(M)$. We define the \textbf{Lie derivative} $\mathcal L_X Y$ of $Y$ 
	with respect to $X$ at $p$ to be the vector:
	\begin{equation}
		(\mathcal L_X Y)_p :=\lim_{t\rightarrow 0}\frac{\phi_{-t*}(Y_{\phi(t)}) - Y_p}{t}
	\end{equation}
	and the \textbf{Lie derivative} $\mathcal L_X\omega$ to be the $k$-covector:
	\begin{equation}
		(\mathcal L_X\omega)_p := \lim_{t\rightarrow 0}\frac{\phi_{-t}^* (\omega_{\phi(t)}) - \omega_{p}}{t}
	\end{equation}
\end{definition}
The idea here is that we transport either $Y$ or $\omega$ along the path of $X$ using the local flow generated by $X$, 
and then use this to define a derivative of the vector field $T$. On functions, the Lie derivative $\mathcal L_X f$ will be the 
exact same as the directional derivative. We can characterize the Lie derivatives of such simple objects as follows.
\begin{theorem}
	Let $X\in\mathfrak X(M)$. 
	\begin{enumerate}
		\item If $f\in C^\infty(M)$, then:
		\begin{equation}
			\mathcal L_X f = Xf
		\end{equation}
		\item If $Y\in\mathfrak X(M)$, then:
		\begin{equation}
			\mathcal L_X Y = [X, Y]
		\end{equation}
	\end{enumerate}
\end{theorem}
Note that $X(f)\in C^\infty(M)$ by evaluation at $p\in M$, i.e. we view it as the map $p\mapsto X_p(f)$. The Lie bracket of 
vector fields is defined to be the vector field $[X, Y]$ given by the following action on $f\in C^\infty(M)$ at $p\in M$:
\begin{equation}
	[X, Y]_p f := (X_p Y - Y_p X) f
\end{equation}
where note that $X(f)\in C^\infty(M), p\mapsto X_p(f)$, so this is a well defined definition. The Lie bracket is 
intimately connected with the coordinate derivative because if $X = a^i\partial_i$ and $Y = b^j\partial_j$ are two vector 
fields, then:
\begin{equation}
	[X, Y] = \left(a^k\partial_k b^i - b^k\partial_k a^i\right)\partial_i
\end{equation}
The Lie bracket here gives $\mathfrak X(M)$ the structure of a \textbf{Lie algebra} $\left(\mathfrak X(M), [\cdot, \cdot]\right)$. 
Intuitively, the Lie bracket is nonzero when the flows generated by $X$ and $Y$ do not commute via parallel transport. When 
$[X, Y]_p$ is nonzero, it ends up being proportional to the infinitesimal parallel transport of a point along the parallelpiped 
defined by $X_p$ and $Y_p$. Finally, we relate some of the properties of the Lie derivative as it acts on differential forms. 

\begin{theorem}
	Let $X\in\mathfrak X(M)$, $\omega\in\Omega^k(M)$, and $\tau\in\Omega^\ell(M)$. 
	\begin{enumerate}
		\item $\mathcal L_X$ is a derivation:
		\begin{equation}
			\mathcal L_X(\omega\wedge\tau) = (\mathcal L_X\omega)\wedge\tau + \omega\wedge(\mathcal L_X\tau)
		\end{equation}
		
		\item $\mathcal L_X$ commutes with the exterior derivative:
		\begin{equation}\begin{tikzcd}
			\Omega^k(M)\arrow[d, "\mathcal L_X"]\arrow[r, "d"] & \Omega^{k + 1}(M)\arrow[d, "\mathcal L_X"] \\
			\Omega^k(M)\arrow[r, "d"] & \Omega^{k + 1}(M)
		\end{tikzcd}\end{equation}
		
		\item $\mathcal L_X$ satisfies a ``product" rule. For $Y_1, ..., Y_k\in\mathfrak X(M)$, we have:
		\begin{equation}
			\mathcal L_X(\omega(Y_1, ..., Y_k)) = (\mathcal L_X\omega)(Y_1, ..., Y_k) + \sum_{i = 1}^k\omega(Y_1, ..., 
			\mathcal L_X Y_i, ..., Y_k)~
			\label{eq:lie_derivative_global}
		\end{equation}
	\end{enumerate}
\end{theorem}

We next define interior multiplication, which is the final operation on forms that we will consider. Luckily for us, unlike the 
Lie derivative, this requires relatively little machinery.
\begin{definition}[Interior multiplication]
	Let $\beta$ be a $k$-covector on a vector space $V$ and $v\in V$. Then for $k\geq 2$, the \textbf{interior multiplication} 
	or \textbf{contraction} of $\beta$ with $v$ is the $(k-1)$ covector:
	\begin{equation}
		\iota_v(\beta)(v_2, ..., v_k) := \beta(v, v_2, ..., v_k)
	\end{equation}
	For $k = 1$, we define $\iota_v(\beta) := \beta(v)\in\mathbb R$ and for $k = 0$, $\iota_v(\beta) := 0$. 
\end{definition}

We see that for $v\in T_p M$, $\iota_v : \Lambda^k(T_p^* M)\rightarrow\Lambda^{k - 1}(T_p^* M)$. Similarly for a 
vector field $X\in\mathfrak X(M)$, we can define an interior derivative pointwise as $\iota_X(\omega)(X_2, ..., X_k) := 
\omega(X, X_2, ..., X_k)$, and so we see that $\iota_X : \Omega^k(M)\rightarrow\Omega^{k - 1}(M)$. Because each 
$\omega\in\Omega^k(M)$ is antisymmetric, note that:
\begin{equation}
	\iota_X^2 = 0
\end{equation}
for each $X\in\mathfrak X(M)$ because $\iota_X^2(\omega)(X_3, ..., X_k) = \omega(X, X, X_2, ..., X_k) = 0$. Thus, 
$\iota_X$ gives $\Omega^*(M)$ the structure of a chain complex:
\begin{equation}\begin{tikzcd}
	...\arrow[r, "\iota_X"] & \Omega^3(M) \arrow[r, "\iota_X"] & \Omega^2(M) \arrow[r, "\iota_X"] & \Omega^1(M) \arrow[r, 
	"\iota_X"] & \Omega^0(M)
\end{tikzcd}\end{equation}
There is a natural duality of $\iota_X$ with the exterior derivative in this manner. Because of this, it is often called the 
\textbf{interior derivative} as well. As a derivative should, it is a graded derivation. For $\omega\in\Omega^k(M)$ and 
$\tau\in\Omega^\ell(M)$:
\begin{equation}
	\iota_X(\omega\wedge\tau) = \iota_X(\omega)\wedge\tau + (-1)^k\omega\wedge\iota_X(\tau)
\end{equation}
The other appearance of a duality between the exterior and interior derivatives is \textbf{Cartan homotopy formula}, which 
states that $\iota_X$ is a cochain homotopy between $\mathcal L_X$ and 0, and likewise $d$ is a chain homotopy between 
$\mathcal L_X$ and 0. 
\begin{theorem}[Cartan homotopy formula]
	For $X\in\mathfrak X(M)$:
	\begin{equation}
		\mathcal L_X = d\iota_X + \iota_X d
	\end{equation}
\end{theorem}
A corollary of this formula is that for any vector field, $\mathcal L_X$ is chain homotopic to the 0 map, and thus $\mathcal 
L_X$ induces the zero map on the de Rham cohomology. 

For $k$-forms with small $k$, computing $\iota_X\omega$ by hand is not too difficult and can be done by brute force. 
However, it is often simpler to do this abstractly, and there is a nice formula to help with computations.
\begin{lemma}
	Let $\alpha^1, ..., \alpha^k$ be 1-covectors on $V$. Then for $v\in V$:
	\begin{equation}
		\iota_v(\alpha^1\wedge ...\wedge\alpha^k) = \sum_{i = 1}^k(-1)^{i + 1}\alpha^i(v)\alpha^1\wedge ...\wedge\hat
		\alpha^i\wedge ...\wedge\alpha^k~
		\label{lemma:int_derivative}
	\end{equation}
\end{lemma}

\begin{example}
	Let $\omega = dx^1\wedge ...\wedge dx^n$ and $X = x^i\partial_i$ on $\mathbb R^n$. To compute $\iota_X\omega$, 
	we could note that $\iota_X\omega\in\Omega^{n - 1}(M)$ and compute $(\iota_X\omega)(X_1, ..., X_{n - 1})$, 
	where $X_i = X_{ij}\partial_j$ are vector fields. This would get extraordinarily unwieldy, so it is simpler to use 
	Equation~\ref{lemma:int_derivative}. We can thus instead compute $dx^i(X) = dx^i(x^j\partial_j) = x^i$, thus:
	\begin{align}
		\iota_X\omega &= \sum_{i = 1}^k (-1)^{i + 1} x^i dx^1\wedge ...\wedge\hat dx^i\wedge ...\wedge dx^n \\
		&= x^1 dx^2\wedge dx^3\wedge ...\wedge dx^n - x^2 dx^1\wedge dx^3\wedge ...\wedge dx^n + ...
	\end{align}
\end{example}

Finally, this new machinery allows us to express the exterior derivative 
$d$ globally without needing to refer to derivatives on a coordinate chart.
\begin{theorem}
	Let $\omega\in\Omega^k(M)$ and $Y_0, Y_1, ..., Y_k\in\mathfrak X(M)$. Then:
	\begin{align}
		(d\omega)(Y_0, ..., Y_k) &= \sum_{i = 1}^k(-1)^i \omega(Y_0, ..., \hat Y_i, ..., Y_k)Y_i \\ 
		&+ \sum_{i < j}(-1)^{i + j}
		\omega([Y_i, Y_j], Y_0, ..., \hat Y_i, ..., \hat Y_j, ..., Y_k)
	\end{align}
\end{theorem}
Note $\hat Y$ means to omit $Y$ from the argument of $\omega$. The proof of this formula is done with induction and 
expressing $(d\omega)(Y_0, ..., Y_k) = (\iota_{Y_0} d\omega)(Y_1, ..., Y_k)$ and using the Cartan homotopy formula 
$\iota_{Y_0} d = (\mathcal L_{Y_0}\omega - d\iota_{Y_0})(Y_1, ..., Y_k)$ and using induction and 
Equation~\ref{eq:lie_derivative_global}. As an example of this formula, we may write the action of the $d\omega$ for a 
1-form $\omega$ explicitly for $X, Y\in\mathfrak X(M)$:
\begin{equation}
	d\omega(X, Y) = X\omega(Y) - Y\omega(X) - \omega([X, Y])
\end{equation}

\begin{example}
	Consider $M = S^1$, and consider $\omega = -y\,dx + x\,dy\in\Omega^1(S^1)$ and $X = -y\,\partial_x + x\,\partial_y\in
	\mathfrak X(S^1)$. Note that since $dim(S^1) = 1$, we must have $d\omega = 2\,dx\wedge dy\in\Omega^2(S^1) \equiv
	0$. Indeed on the circle we can see this because since the coordinates are defined by $x^2 + y^2 = R^2$, $x\,dx + 
	y\,dy = 0$, hence wedging with $dx$ we see $dx\wedge dy = 0$ when $y\neq 0$ (and when $x\neq 0$ by wedging with 
	$dy$). Thus we of course have $d\omega = 0$, although it does not appear to vanish immediately from the computation. 
	We can then compute $\mathcal L_X\omega = (d\iota_X + \iota_X d)\omega = d\iota_X\omega$:
	\begin{equation}
		\mathcal L_X\omega = d\iota_X\omega = d(\omega(X)) = d(y^2 + x^2) = d(R^2) = 0
	\end{equation}
	
\end{example}

\newpage
\subsection{Summary}

There were a lot of definitions introduced in this section, so I will summarize the major definitions and results here for a 
manifold $M$ of dimension $n$.
\begin{itemize}
	\item The \textbf{cotangent space} at $p\in M$ is the dual to the tangent space $T_p M$:
	\begin{equation}
		T_p^* M := Hom(T_p M, \mathbb R)
	\end{equation}
	A basis for this space is $\{dx^i\}_{i = 1}^n$, and the dual vectors obey $dx^i(\partial_j) = \delta^i_j$, where $d$ is the 
	differential map $d : C^\infty(M)\rightarrow\Omega^1(M)$ defined by its action on a vector field $X\in\Gamma(TM)$:
	\begin{equation}
		(df)(X) := X(f)
	\end{equation}
	The differential can also be expressed in any chart $(U, x^i)$ as:
	\begin{equation}
		df = \frac{\partial f}{\partial x^i} dx^i
	\end{equation}
	
	\item A \textbf{$k$-covector} $\omega_p$ at a point $p\in M$ is an element of the $k$th exterior power of the cotangent 
	space at $p$ is: 
	\begin{equation}
		\omega_p\in\Lambda^k\left(T_p^* M\right) = span\left\{dx^{i_1}\wedge ...\wedge dx^{i_k} : 1\leq i_1 < ... < i_k\leq n 
		\right\}
	\end{equation}
	A basis for this space is $\{dx^{i_1}\wedge ...\wedge dx^{i_k}\}_{(i_j)\in\mathfrak I_k^n}$, and the dimension is $n\choose 
	k$. 
	
	\item The \textbf{$k$th exterior power of the cotangent bundle} is:
	\begin{equation}
		\Lambda^k\left(T^* M\right) :=\coprod_{p\in M}\Lambda^k\left(T_p^* M\right)
	\end{equation}
	
	\item A \textbf{differential form} $\omega$ of rank $k$ is a section of the $k$th exterior power of the cotangent bundle:
	\begin{equation}
		\omega\in\Omega^k(M) := \Gamma(\Lambda^k(T^* M))
	\end{equation}
	and can be expressed as $\omega = a_{i_1, ..., i_k} dx^{i_1}\wedge ...\wedge dx^{i_k}$. 
	
	\item The \textbf{wedge product} of two differential forms $\omega\in\Omega^k(M), \tau\in\Omega^\ell(M)$ is defined 
	pointwise as:
	\begin{equation}
		(\omega_p\wedge\tau_p)(v_1, ..., v_{k + \ell}) := \sum_{\sigma\in\mathfrak S_{k, \ell}} sgn(\sigma)
		\omega_p(v_{\sigma(1)}, ..., v_{\sigma(k)})\tau_p(v_{\sigma(k + 1)}, ..., v_{\sigma(k + \ell)})
	\end{equation}
	This naturally gives $(\Omega^k(M), +, \cdot, \wedge)$ the structure of a $\mathbb R$-algebra. 
	
	\item Given a smooth map $f : M\rightarrow N$, we induce a \textbf{pullback map} of differential forms $f^* : \Omega^k(N)
	\rightarrow\Omega^k(M)$ which acts on vector fields as:
	\begin{equation}
		f^*(\omega)(X_1, ..., X_k) = \omega(f_* X_1, ..., f_* X_k)
	\end{equation}
	Furthermore, $f^*$ is a homomorphism of algebras and a chain map on the de Rham complex $(\Omega^*(M), d)$. 
	
	\item The \textbf{exterior derivative} is a coboundary map $d : \Omega^k(M)\rightarrow\Omega^{k + 1}(M)$ defined as 
	$df = (\partial f / \partial x^i)dx^i$ on $f\in\Omega^0(M)$ and:
	\begin{equation}
		d\omega := dg_{i_1, ..., i_k}\wedge dx^{i_1}\wedge ...\wedge 
		dx^{i_k}
	\end{equation}
	on $\omega = g_{i_1, ..., i_k} dx^{i_1}\wedge...\wedge dx^{i_k}\in\Omega^k(M)$. 
	
	\item Given $X\in\mathfrak X(M)$, the \textbf{interior derivative} is a boundary map $\iota_X : \Omega^k(M)
	\rightarrow\Omega^{k - 1}(M)$ defined as:
	\begin{equation}
		\iota_X(\omega)(X_2, ..., X_k) := \omega(X, X_2, ..., X_k)
	\end{equation}
	
	\item Given $X\in\mathfrak X(M)$, the \textbf{Lie derivative} measures the infinitesimal change in a tensor field as it 
	flows along $X$. On a differential form $\omega\in\Omega^k(M)$:
	\begin{equation}
		(\mathcal L_X\omega)_p := \lim_{t\rightarrow 0}\frac{\phi_{-t}^* (\omega_{\phi(t)}) - \omega_p}{t}
	\end{equation}
	where $\phi_t(p)$ is the flow generated by $X$ at $p$, so $\phi_0(p) = p$ and $\phi_t(p)$ is an integral curve to $X$. 
	
	\item The derivatives are all related via the \textbf{Cartan homotopy formula}:
	\begin{equation}
		\mathcal L_X = d\iota_X + \iota_X d
	\end{equation}
\end{itemize}

\newpage
\section{Integration}

Differential forms exist to be integrated over. Since a $k$-form generalizes a notion of a $k$-dimensional volume, we 
can only integrate $k$-forms over a $k$-dimensional subset of a manifold. These forms are called \textbf{top forms}:
\begin{definition}[Top form]
	A \textbf{top form} on a $k$-dimensional manifold $M$ is a $k$-form $\omega\in\Omega^k(M)$. 
\end{definition}
Before discussing how to integrate a differential form, we must discuss orientations on a manifold. Forms may only be 
integrated over an oriented manifold, and we will make that notion precise.

\subsection{Orientation}

Let $V$ be a vector space of dimension $n$. We denote an ordered subset of $V$ by $[v_1, ..., v_n]$, as opposed to the 
typical unordered subset $\{v_1, ..., v_n\}$. Let $u = [u_1, ..., u_n]$ and $v = [v_1, ..., v_n]$ be two ordered bases for $V$. 
We say that $u$ is \textbf{equivalent} to $v$ iff $u = vA$ with $det(A) > 0$, and we write $u\sim v$ in this case. This forms an 
equivalence relation on the space of ordered bases of $V$, and we define an \textbf{orientation} on $V$ to be an equivalence 
class of ordered bases on $V$. There are two orientations on any vector space; a positive one, and a negative one, and one 
can get between ordered bases of the same orientation by a positive change of basis. 

Orientations are nicely related to $n$-covectors on a space. Suppose that two ordered bases are related by $u_j = v_i A_{ij}$. 
Then for any $n$-covector $\beta$ on $V$, we have:
\begin{equation}
	\beta(u_1, ..., u_n) = det(A)\beta(v_1, ..., v_n)
\end{equation}
This implies that $u\sim v$ iff $\beta(u_1, ..., u_n)$ and $\beta(v_1, ..., v_n)$ have the same sign for any covector 
$\beta$. In this case, we say that $\beta$ \textbf{determines} the orientation $[v_1, ..., v_n]$ when $\beta(v_1, ..., v_n) > 0$. 
This is well defined because if $\beta$ determines the orientation $v$ and $u\sim v$, then $\beta$ also determines the 
orientation $u$ as well because $u = vA$ and $\beta(u) = det(A)\beta(v)$ with $det(A) > 0$. Furthermore, any 
multiple $a\beta$ with $a > 0$ \textbf{specifies the same orientation as $\beta$} because $a\beta(v)$ will have the 
same sign as $\beta(v)$. So, we say two $n$-covectors $\alpha$ and $\beta$ are \textbf{equivalent}, $\alpha\sim\beta$, 
iff $\alpha = a\beta$ with $a > 0$. Note that any two $n$-covectors are multiples of one another because $dim(\Lambda^n(V)) 
= 1$. An orientation on $V$ can thus be viewed as an equivalence class of ordered bases, or an equivalence class of 
$n$-covectors. 

Now we work with a manifold $M$ of dimension $n$. Recall a frame on an open set $U\subseteq M$ is a choice of $n$
vector fields $X_1, ..., X_n\in\mathfrak X(U)$ such that $\{X_{1, p}, ..., X_{n, p}\}$ is linearly independent (forms a basis) 
at each $p\in U$. We can take this to an equivalence relation on frames $(X_1, ..., X_n)$ and $(Y_1, ..., Y_n)$ by decreeing:
\begin{equation}
	(X_1, ..., X_n)\sim (Y_1, ..., Y_n)\iff \forall p\in U, \;(X_{1, p}, ..., X_{n, p})\sim (Y_{1, p}, ..., Y_{n, p})
\end{equation}
A \textbf{pointwise orientation} $\mu$ assigns an orientation to each $p\in M$, i.e. $\mu = [X_1, ..., X_n]$ with $\mu_p = 
[X_{1, p}, ..., X_{n, p}]$. The vector fields contained in $\mu$ do not need to be continuous, but it is only interesting when 
they are continuous. Note that a pointwise orientation is global and assigns an orientation to each tangent space on $M$. 
\begin{definition}
	A continuous pointwise orientation on $M$ is called an \textbf{orientation} on $M$. If $M$ has an orientation, we call 
	$M$ \textbf{orientable}. 
\end{definition}
\begin{theorem}
	A connected orientable manifold $M$ has precisely two orientations. 
\end{theorem}
\begin{theorem}
	A pointwise orientation $[X_1, ..., X_n]$ on $M$ is continuous iff at each $p\in M$, there is a chart $(U, x^i)$ containing 
	$p$ such that the function:
	\begin{equation}
		(dx_1\wedge ...\wedge dx_n)(X_1, ..., X_n) : U\rightarrow\mathbb R
	\end{equation}
	is positive at each $q\in U$. 
\end{theorem}

This leads to a classification theorem for a manifold being orientable. We can instead simply look at the top forms on $M$, 
and there is a simple condition on these top forms for us to see if $M$ is orientable.
\begin{theorem}
	An $n$-dimensional manifold $M$ is orientable iff there exists a $C^\infty$ nowhere vanishing $n$-form on $M$. 
\end{theorem}
\begin{proof}
Given an orientable $M$, we can use the previous theorem and a partition of unity to ``stitch" together 
the forms in the previous theorem into a single continuous top form which vanishes nowhere. In the other direction, 
suppose that $\omega$ vanishes nowhere. At each $p\in M$, we can find $[X_{1, p}, ..., X_{n, p}]$ such that $\omega_p
(X_{1, p}, ..., X_{n, p}) > 0$. Then for any chart $(U, x^i)$ containing $p$, we can write $\omega = f\;dx^1\wedge ...\wedge 
dx^n$ where $f$ is continuous and nowhere vanishing, hence $f > 0$ or $f < 0$ on $U$. If $f > 0$, then $\omega(X_1, ..., 
X_n) > 0$ everywhere on $U$, and if $f < 0$, then $-\omega(X_1, ..., X_n) > 0$ everywhere on $U$, and we can 
apply the previous theorem.
\end{proof}
Thus on an orientable manifold $M$, there are two types of top forms-- forms which are everywhere positive, and forms which 
are everywhere negative. 
\begin{definition}
	Let $\omega\in\Omega^n(M)$ be a top form. We call $\omega$ an \textbf{orientation (volume) form} if $\omega$ is 
	nowhere vanishing, i.e. $\omega_p\neq 0$ at any $p\in M$. If we have an ordered frame $[X_1, ..., X_n]$ such that 
	$\omega(X_1, ..., X_n) > 0$, we say that $\omega$ \textbf{specifies} the orientation $[X_1, ..., X_n]$. 
\end{definition}
We can partition the volume forms on $M$ into two equivalence classes: let $\omega\sim\omega'$ iff $\omega = f\omega'$ 
with $f > 0$ everywhere. Then \textit{each equivalence class of this relation exactly specifies an orientation of $M$}. 
Note in coordinates, one orientation form is given by $dx^1\wedge ...\wedge dx^n$, and the other is $-dx^1\wedge ...
\wedge dx^n$. We will write an oriented manifold as a pair $(M, [\omega])$, where $\omega$ is a volume form on $M$ 
specifying the positive orientation. 

A diffeomorphism $f : (M, [\omega_M])\rightarrow (N, [\omega_N])$ is \textbf{orientation preserving} if $[f^*\omega_N] = 
[\omega_M]$. On charts $U\subseteq M$ and $V\subseteq N$, this is equivalent to the Jacobian:
\begin{equation}
	\det\left\{\frac{\partial F^i}{\partial x^j}\right\}
\end{equation}
being everywhere positive on $U$. Given an orientable manifold $M$, we can find an oriented atlas on $M$, i.e. an atlas 
such that for any two overlapping charts $(U, x^i)$ and $(V, y^i)$, the Jacobian $\det\{\partial y^i / \partial x^j\} > 0$ 
everywhere. 

An orientation allows us to integrate a manifold. Before we dive into integration, we must define orientations on the 
boundaries of manifolds, as this will allow us to formulate Stokes's theorem rigorously. Recall on a manifold with 
boundary, the points in $\partial M$ have coordinate neighborhoods diffeomorphic to a point on the boundary of 
$\mathcal H^n$, where $\mathcal H^n := \{(x_1, ..., x_n) : x_n\geq 0\}$ is the Euclidean half-plane. 

Defining the tangent space to a manifold with boundary is slightly different than that on a manifold without boundary, 
because $\partial M$ is a $(n - 1)$ degree manifold, i.e. $dim(T_p(\partial M)) + 1 = dim(T_p M)$. However, since we defined 
the tangent space on a manifold with regards to derivations on the entire manifold, if $p\in \partial M$, the tangent space 
to $p$ in $M$ is $n$-dimensional and \textit{still includes derivative operators which point away from the boundary}. 
So, one must be careful to specify if we are considering $T_p M$ or $T_p\partial M$ when $p\in\partial M$; for our 
considerations we will want the full $n$-dimensional tangent space $T_p M$, but one may also examine the $(n - 1)$ 
dimensional tangent space $T_p\partial M$. 

\begin{definition}
	Let $M$ be an $n$-dimensional manifold with boundary and $p\in M$. We say that a tangent vector $X_p\in T_p M$ is 
	\textbf{inward-pointing} if $X_p\not\in T_p\partial M$ and if there is $\epsilon > 0$ and a curve $\gamma : [0, \epsilon)
	\rightarrow M$ such that $\gamma(0) = p$ and $\gamma'(0) = X_p$. We say $X_p$ is \textbf{outward-pointing} if 
	$-X_p$ is inward pointing. 
\end{definition}
An inward pointing vector on the boundary is literally what it sounds like; for example, in $\mathcal H^3 = \mathbb R^3_{z\geq 
0}$, an inward pointing vector at $\vec 0$ is $\partial_z$, while an outward pointing vector is $-\partial_z$. 
\begin{theorem}
	On a manifold $M$ with boundary $\partial M$, there is a smooth outward pointing vector field along $\partial M$. 
\end{theorem}
An outward pointing vector field allows us to push an orientation for $M$ onto an orientation for $\partial M$ by means 
of the interior derivative. 
\begin{theorem}
	Let $(M, [\omega])$ be an oriented $n$ dimensional manifold with boundary. If $\omega$ is a volume form on $M$ 
	representing the positive orientation and $X$ is a 
	smooth outward pointing vector field on $\partial M$, then $\iota_X\omega$ is a smooth nowhere vanishing $(n - 1)$ 
	form on $\partial M$, and hence $\partial M$ is orientable. ~
	\label{thm:boundary}
\end{theorem}
\begin{definition}
	In the notation of Theorem~\ref{thm:boundary}, we define the \textbf{boundary orientation} on $\partial M$ to 
	be $[\iota_X\omega]$, the orientation specified by $\iota_X\omega$. 
\end{definition}
\begin{corollary}
	Let $p\in\partial M$ and $X_p\in T_p M$ be outward-pointed. Then an ordered basis $[v_1, ..., v_{n - 1}]$ for $T_p
	\partial M$ represents the boundary orientation at $p$ iff the ordered basis $[X_p, v_1, ..., v_{n - 1}]$ for $T_p M$ 
	represents the orientation on $M$ at $p$. 
\end{corollary}
In the manner of these theorems, this allows us to endow the boundary of an oriented manifold with an orientation which 
respects the orientation of $M$. Remember that it is conventional for the normal vector field to be put first in such an 
orientation: as Tu says, remember the mnemonic ``outward vector first". 

\begin{example}
	Consider the boundary orientation on $\mathcal H^n$ induced by the positive orientation $\omega := dx^1\wedge ...
	\wedge dx^n$. An outward pointed vector is $X := -\partial_n$, and we can contract this with the volume form to get 
	the boundary orientation form:
	\begin{equation}
		\iota_{X}\omega = (-1)^{n + 1}dx^n(-\partial_n) dx^1\wedge ... \wedge dx^{n - 1} = (-1)^n dx^1\wedge ...\wedge 
		dx^{n - 1}
	\end{equation}
	For $\mathcal H^3$, the boundary orientation form is thus $\iota_X\omega = (-1)^3 dx\wedge dy = dy\wedge dx$. Note 
	the negative here is because we have put the $-\partial_z$ vector in first from the prescription for the boundary 
	orientation, so our ordered basis is $[-\partial_z, \partial_y, \partial_x]\sim [\partial_x, \partial_y, \partial_z]$. 
\end{example}

\subsection{Integration}

Integrating over forms follows in a natural way from integrating over $\mathbb R^n$, since a manifold is locally 
homeomorphic to $\mathbb R^n$. In Euclidean space, we integrate $n$-forms over $\mathbb R^n$. Suppose 
$\omega\in\Omega^n(\mathbb R^n)$ is an $n$-form. Then we may express $\omega$ in the standard coordinates 
of $\mathbb R^n$ as $\omega = f(x)\,dx^1\wedge ...\wedge dx^n$, and we define the \textbf{integral} of $\omega$ 
over $\mathbb R^n$ to be:
\begin{equation}
	\int_{\mathbb R^n}\omega = \int_{\mathbb R^n} f(x)\,dx^1\wedge ...\wedge dx^n := \int_{\mathbb R^n} f(x)\,d^nx
\end{equation}
where $d^nx$ is the standard Lebesgue measure on $\mathbb R^n$ and the last integral is the usual Lebesgue integral. 
So, integration of a form in $\mathbb R^n$ essentially amounts to forgetting the wedge products between the differentials. 
Because of the wedge product, integrating forms remembers the orientation of the form, i.e. $\int f(x)\,dx^2\wedge dx^1 = 
-\int f(x)\,dx^1\wedge dx^2$. 

Now we are in position to define an integral over a $n$-dimensional manifold $M$. We may only integrate top forms with 
compact support so that we are guaranteed the integral converges. We denote the set of $k$-forms on $M$ with compact 
support by $\Omega^k_C(M)$.

Let $(U, \phi)$ be a chart on $M$, and $\omega\in\Omega^n_C(U)$. Because $\phi : U\rightarrow\phi(U)$ is a 
diffeomorphism, the pullback $(\phi^{-1})*\omega$ is a $n$-form on $\mathbb R^n$, so we can integrate it. We thus define:
\begin{equation}
	\int_U\omega := \int_{\phi(U)}\left(\phi^{-1}\right)^*\omega
\end{equation}
where $\phi(U)\subseteq\mathbb R^n$ and the integral on the right is the previously defined integral. 

We can use a partition of unity on $M$ to extend this definition to an integral over the total manifold. Let $\{U_\alpha, 
\phi_\alpha\}$ be an oriented atlas on $M$, and let $\{\rho_\alpha\}$ be a partition of unity subordinate to $\{U_\alpha\}$. 
Recall that by definition for, any differential form $\omega$ satisfies $\omega = \sum_\alpha\rho_\alpha\omega$. 
\begin{definition}[Integral of a differential form]
Let $\omega\in\Omega^n_C(M)$. We define the \textbf{integral} of $\omega$ over $M$ to be:
\begin{equation}
	\int_M\omega := \sum_\alpha\int_{U_{\alpha}}\rho_\alpha\omega
\end{equation}
\end{definition}

This definition can be shown to be independent of choice of atlas and partition of unity, and so is well defined. Although 
the definition is intuitively nice, it is often difficult to use this to compute actual integrals. In practice, it is often 
easier to find a parameterization of a manifold $M$. A \textbf{parameterization} of $M$ is a subset $A\subseteq M$ and a 
$C^\infty$ map $F : D\rightarrow M$, where $D\subseteq\mathbb R^n$ is compact such that $A = im(F)$ and $F$ 
restricts to an orientation preserving diffeomorphism on $int(D)$ to $F(int(D))$. The integral of $\omega\in\Omega^n(M)$ 
can thus be calculated over $A$ as follows:
\begin{equation}
	\int_A\omega = \int_D F^*\omega
\end{equation}

\begin{example}
	We can integrate the area form over the sphere $S^2$. This form is defined as:
	\begin{equation}
		\omega = \begin{cases}
			\frac{dy\wedge dz}{x} & x\neq 0 \\
			\frac{dz\wedge dx}{y} & y\neq 0 \\
			\frac{dx\wedge dy}{z} & z\neq 0
		\end{cases}
	\end{equation}
	We compute $\int_{S^2}\omega$ by parameterizing the sphere with the coordinates $F : [0, 2\pi]\times [0, \pi]
	\rightarrow S^2$ by:
	\begin{equation}
		F(\phi, \theta) = (\sin\theta\cos\phi, \sin\theta\sin\phi, \cos\theta)
	\end{equation}
	We must compute the pullback $F^*\omega$. Note that $F^* x = x\circ F : [0, 2\pi]\times [0, \pi]\rightarrow\mathbb 
	R$ is given by $(F^* x)(\phi, \theta) = \sin\theta\cos\phi$. Similarly, $F^* y = \sin\theta\sin\phi$, and $F^* z = \cos\theta$. 
	We also have $F^* dy = dF^*y = d(\sin\theta\sin\phi) = \cos\theta\sin\phi\,d\theta + \sin\theta\cos\phi\,d\phi$, and 
	$F^* dz = dF^* z = d\cos\theta = -\sin\theta\,d\theta$. So:
	\begin{equation}
		F^*\omega = \frac{F^*(dy)\wedge F^*(dz)}{F^*x} = \frac{(\sin\theta\cos\phi\,d\phi)\wedge (-\sin\theta\,d\theta)}{\sin
		\theta\cos\phi} = \sin\theta\,d\theta\wedge d\phi
	\end{equation}
	Therefore:
	\begin{equation}
		\int_{S^2}\omega = \int_{[0, 2\pi]\times [0, \pi]}\sin\theta\,d\theta\wedge d\phi = \int_0^{2\pi} d\phi\int_0^\phi d\theta
		\,\sin\theta = 4\pi
	\end{equation}
\end{example}

Note integration over a form $\omega$ induces a premeasure $\mu_\omega$ on the Borel sets (which are generated by 
the open sets on a topological space) by:
\begin{equation}
	\mu_\omega(U) :=\int_U\omega
\end{equation}
The important thing to note is that integrating differential forms is different than integrating a function on a measure space 
because of the domain of integration. In measure theory, we integrate a function over a subset of the measure space. 
In particular, we have no notion of an ``oriented volume", and instead just have an absolute notion of measure. When 
integrating a differential form, we have an implicit notion of orientation that comes built into our framework. Technically, 
the domain of integration is not a subset of a manifold; rather, it is an \textit{oriented subset of $M$}, given formally 
by an equivalence class of orientation forms $[M] = (M, [\omega])$. 

We end this section with Stokes' Theorem, which fully generalizes the fundamental theorem of calculus to manifolds. 
As a corollary to this theorem, it is easy to prove most of the nice multivariable integration theorems that you studied way 
back when in multivariable calculus.
\begin{theorem}[Stokes' Theorem]
	Let $M$ be a smooth $n$ dimensional manifold, and $\omega\in\Omega_C^{n - 1}(M)$. Then:
	\begin{equation}
		\int_M d\omega = \int_{\partial M}\omega
	\end{equation}
	where $\partial M$ is realized with the boundary orientation.
\end{theorem}

In particular, if $M$ has no boundary, then any exact form $\omega = d\tau$ integrates to 0 across $M$, $\int_M \omega = 0$. 
\begin{example}[Vector calculus in $\mathbb R^3$]
	Let us study the exterior algebra in $\mathbb R^3$. We have four nonzero graded subsets of $\Omega^*(M)$. 
	$\Omega^0(M)$ is 1-dimensional and is identified with functions $f(x)$. Similarly, $\Omega^3(M)$ is 
	one-dimensional and can also be identified with functions $f(x)\leftrightarrow f(x)\,dx\wedge dy\wedge dz$. 
	$\Omega^1(M)$ and $\Omega^2(M)$ can both be identified with vector fields $\vec f(x) := f_1(x)\hat x + f_2(x)\hat y + 
	f_3(x)\hat z$. In $\Omega^1(M)$, $\vec f\leftrightarrow f_1\,dx + f_2\,dy + f_3\,dz$, and in $\Omega^2(M)$ 
	the identification is $\vec f\leftrightarrow f_1 \,dy\wedge dz + f_2\, dz\wedge dx + f_3\, dx\wedge dy$. We can compute 
	the differential on these different functions. On $\Omega^0(M)$:
	\begin{equation}
		df = (\partial_i f)dx^i\leftrightarrow \partial_i f\,\hat x_i
	\end{equation}
	and we see this is the standard gradient! On $\Omega^1(M)$:
	\begin{align}
		d(f_1\,dx + f_2\, dy + f_3\, dz) &= \left(\partial_y f_3 - \partial_z f_2\right)dy\wedge dz + \left(\partial_z f_1 - 
		\partial_x f_3\right)dz\wedge dx + \left(\partial_x f_2-\partial_y f_1\right)dx\wedge dy \nonumber\\
		&\leftrightarrow\nabla\times\vec f
	\end{align}
	which is the curl of the vector field. Similarly, on 2 forms:
	\begin{equation}
		d(f_1\,dy\wedge dz + f_2\,dz\wedge dx + f_3\,dx\wedge dy) = (\partial_x f_1 + \partial_y f_2 + \partial_z f_3)\,
		dx\wedge dy\wedge dz \leftrightarrow\nabla\cdot\vec f
	\end{equation}
	So, we see that every time we use multivariable calculus, we are secretly using the machinery of differential forms. 
	The reason that this is not immediately obvious is because the exterior powers of $\mathbb R^3$ have similar 
	dimensions, and we identify the 3-dimensional powers as vector fields and the 1-dimensional powers as standard
	functions. 
\end{example}

\section{de Rham Cohomology}

The exterior derivative provides a powerful structure on differential forms; as mentioned earlier, the fact that $d^2 = 0$ gives 
$\Omega^*(M)$ the structure of a cochain complex. Accordingly, we can take the cohomology of this complex. We start 
with some terminology.
\begin{definition}
	Let $\omega\in\Omega^k(M)$ be a $k$-form. If $d\omega = 0$, we say that $\omega$ is \textbf{closed}. If $\omega = 
	d\tau$ for $\tau\in\Omega^{k - 1}(M)$, we say that $\omega$ is \textbf{exact}. Let $Z^k(M)$ be the space of closed 
	$k$-forms, and $B^k(M)$ be the space of exact $k$-forms. Then the \textbf{$k$th de Rham cohomology of $M$} is 
	defined to be the vector space:
	\begin{equation}
		H^k(M) := Z^k(M) / B^k(M)
	\end{equation}
\end{definition}

Because $\Omega^k(M)$ vanishes for $k > n$, $H^k(M)$ also vanishes for $k > n$. For $k = 0$, we can classify 
the cohomology group $H^0(M)$.
\begin{theorem}
	Suppose $M$ has $r$ connected components. Then:
	\begin{equation}
		H^0(M) = \mathbb R^r
	\end{equation}
\end{theorem}
\begin{proof}
	Since $B^0(M) = 0$, $H^0(M) = Z^0(M)$, and we must classify the closed $0$-forms. Recall that 0-forms on a manifold 
	are canonically isomorphic to functions on a manifold. So, let $f\in Z^0(M)$. Then:
	\begin{equation}
		df = \partial_i f\, dx^i = 0\implies \forall i,\,\partial_i f = 0
	\end{equation}
	This implies $f$ is locally constant, and therefore must be constant on each component of $M$. Because $M$ has $r$ 
	components $M = \coprod_{i = 1}^r M_i$ with $M_i\cap M_j = \emptyset$ for $i\neq j$, a basis for $Z^0(M)$ are the 
	functions $\{f^i : M\rightarrow\mathbb R\}_{i = 1}^r$ such that $f^i(x) = 1$ when $x\in M^i$ and $f^i = 0$ when $x\not\in 
	M^i$. Thus, $Z^0(M) = \mathbb R^r$. 
\end{proof}

The wedge product $\wedge$ gives the de Rham cohomology the structure of an algebra over $\mathbb R$, $(H^*(M), +, 
\cdot, \wedge)$. 

\subsection{Singular Cohomology}

Recall the singular homology (integral coefficients) of a topological space $X$. We defined $Sin_n(X) := \{\sigma : 
\Delta^n\rightarrow X\; | \;\sigma\textnormal{ is continuous.}\}$, then took the free abelian group $S_n(X) := \mathbb Z 
Sin_n(X)$ generated by the $n$-simplices in $X$. These are called $n$-chains in $X$. This space has a natural structure of a 
chain complex given by the boundary operator $\partial : \Delta^n\rightarrow\Delta^{n - 1}$ sending each simplex to its 
boundary, and the \textbf{singular homology} is defined to be the homology of this chain complex.

One can dualize the $n$-chains in $X$ to get a cochain complex:
\begin{equation}
	S^n(X; \mathbb Z) := Hom(S_n(X), \mathbb Z)
\end{equation}
This converts the chain complex $(S_*(X), \partial)$ into a cochain complex $(S^*(X), \delta)$, and the cohomology of this 
cochain complex is called the \textbf{singular cohomology} of $X$. Note that a cochain $f\in S^n(X)$ is a map $f : 
S_n(X)\rightarrow\mathbb Z$, so $f(\sigma)$ is an integer. Furthermore, the coboundary map $\delta$ is dual to the 
boundary map $\partial$ in the following manner:
\begin{equation}
	(\delta f)(\sigma) = f(\partial\sigma)
\end{equation}
where $f\in S^n(X; \mathbb Z)$ and $\sigma\in S_{n + 1}(X)$. 

There are a variety of pairings on singular (co)homology that are of interest to us. Of primary interest will be the cup product, 
which will endow $S^*(X, \mathbb Z)$ with a ring structure. 

Singular cohomology is often the first introduction to cohomology that one sees in an algebraic topology course; we are 
discussing it now because there is a natural isomorphism between the de Rham cohomology and the singular cohomology 
of a manifold. 
\begin{theorem}[de Rham]
	Let $M$ be a $n$-manifold. Then the singular cohomology with real coefficients $H^*(M; \mathbb R)$ and the 
	de Rham cohomology $H_{DR}^*(M)$ are isomorphic as rings. The isomorphism is explicitly given by the map:
	\begin{align}
		\gamma^* : H_{DR}^*(M)&\rightarrow H^*(M; \mathbb R) \\
		[\omega] &\mapsto \left([\sigma]\mapsto \int_\sigma\omega\right)
	\end{align}
\end{theorem}
To define this map, one works at the level of the cochain complexes. Define the map $\gamma : \Omega^k(M)\rightarrow 
S^k(M; \mathbb Z)$ by $\gamma(\omega)(\sigma) := \int_\sigma\omega$ for $\sigma\in S_k(M)$. Then we must show 
that $\gamma$ is a chain map, as then $\gamma$ will drop to a homomorphism on the homology groups $\gamma^* : 
H_{DR}^*(M)\rightarrow H^*(M; \mathbb R)$. 
\begin{equation}\begin{tikzcd}
	...\arrow[r, "d"] & \Omega^{k - 1}(M)\arrow[d, "\gamma"]\arrow[r, "d"] & \Omega^{k}(M)\arrow[d, "\gamma"]\arrow[r, "d"] 
	& \Omega^{k + 1}(M)\arrow[d, "\gamma"]\arrow[r, "d"] & ... \\
	... \arrow[r, "\delta"] & S^{k - 1}(M; \mathbb R) \arrow[r, "\delta"] & S^{k}(M; \mathbb R) \arrow[r, "\delta"] & 
	S^{k + 1}(M; \mathbb R) \arrow[r, "\delta"] & ...
\end{tikzcd}\end{equation}
The fact that $\gamma$ is a chain map is directly due to Stokes' theorem. For $\omega\in\Omega^k(M)$ and 
$\sigma\in S_{k + 1}(M)$, we have:
\begin{equation}
	(\gamma d)(\omega)(\sigma) = \gamma(d\omega)(\sigma) = \int_\sigma d\omega = \int_{\partial\sigma}\omega = 
	\gamma(\omega)(\partial\sigma) = (\delta\gamma)(\omega)(\sigma)
\end{equation}
This shows that $\gamma$ is a chain map and therefore induces a homomorphism $\gamma^*$ in cohomology. 

\section{Applications to physics}

\subsection{Electromagnetism}

Problem 19.13 in Tu is a good start for this. 

\subsection{Relativity}

\end{document}